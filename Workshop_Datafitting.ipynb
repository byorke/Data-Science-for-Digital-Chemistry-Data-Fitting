{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b5986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96b6d5e9",
   "metadata": {},
   "source": [
    "# Workshop 4a\n",
    "\n",
    "Author: Andrew Burnett, Stuart Warriner & Briony Yorke\n",
    "\n",
    "### Advanced Plotting and Fitting\n",
    "\n",
    "In this exercise we're going to expand on our knowledge of plotting and manipulating data with a focus on performing linear and non-linear fitting. You can start by running the code cell below to import the packages we need. As well of the ones you will be familiar with, we are going to use scipy for the first time.\n",
    "\n",
    "In the terminal run pip3 install scipy, you may need to restart VSCode.\n",
    "\n",
    "Run the code cell below to import the packages you'll be using in this workshop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a32a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.8.17' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# import the pyplot module from matplotlib, pandas, numpy and additional tools that you will need and give them an alias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import some additional modules from matplotlib\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# import packages from scipy that we will be using for fitting\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "print(\"cell executed and packages imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ce4cc",
   "metadata": {},
   "source": [
    "We are going to start by creating a toy linear dataset with some noise. Please run the code below. This does the following things:\n",
    "\n",
    "- generates a data set called x which are 50 values evenly spaced between 0 and 10\n",
    "- sets a fixed random seed so the noise you generate will be the same everytime\n",
    "- generates a set of y values where $y=2.5x + 1.0$ and then adding some random noise to the datapoints so there not perfectly straight\n",
    "\n",
    "This means we end up with a data set in the form:\n",
    "\n",
    "$$ y= mx +c $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate linear data with some noise\n",
    "\n",
    "x = np.linspace(0, 10, 50)\n",
    "\n",
    "# set random seed so the random numbers are the same each time\n",
    "\n",
    "# Create a generator with a fixed seed for reproducibility\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# produce a linear relationship with gradient 2.5 and intercept 1.0 plus some random noise\n",
    "y = 2.5 * x + 1.0 + rng.normal(scale=1.0, size=x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981dd30",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc2fd1b127fb0483",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Plot the Data\n",
    "\n",
    "In the code cell below please replace ___ where appropriate to fill in the blanks. This function should plot the x and y data on a scatter plot. Use the ```plt.subplots()``` function to do this and add, axis labels, titles and legend. You might want to check workshop 4 to help you remember how to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create subplots\n",
    "fig, ax = ___.___()\n",
    "\n",
    "# plot the data as a scatter plot\n",
    "ax.scatter(x, y, label='Data Points')\n",
    "\n",
    "\n",
    "# set the title of the plot \n",
    "___.___(___)\n",
    "\n",
    "# set the x-axis and y-axis labels\n",
    "___.___(___)\n",
    "___.___(___)\n",
    "\n",
    "# set legend and show plot\n",
    "___.___()\n",
    "___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035803c0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce26e95f7e0ed0e0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Fit the data using linear regression.\n",
    "\n",
    "We now want to fit a straight line through this data using a statistical methods called **Linear regression** which is used to model the relationship between a dependent variable ($y$) and one or more independent variables (in this case $x$). The goal is to find the best-fitting straight line (called the regression line) through the data points.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Fit the Line:** The algorithm calculates the best values for $m$ and $c$ by minimizing the **sum of squared errors** between the predicted and actual values.\n",
    "2. **Make Predictions:** Once the line is fitted, you can use it to predict $y$ for new values of $x$.\n",
    "3. **Evaluate Performance:** We then need to check how well the prediction fits the data and there are many common metrics to do this \n",
    "\n",
    "To do this we care going to use ```lingress``` from SciPy's <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html\">stats</a> package. \n",
    "\n",
    "Here we run the code pass the x and y information to lingress and obtain the result\n",
    "\n",
    ">```\n",
    ">result = linregress(x, y)\n",
    ">```\n",
    "\n",
    "result is a dataset that contains the following outputs\n",
    "\n",
    "- slope: The slope of the regression line.\n",
    "- intercept: The intercept of the regression line.\n",
    "- rvalue: Correlation coefficient - this is one way of estimating how well the fit has performed\n",
    "- pvalue: Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero.\n",
    "- stderr: Standard error of the estimated gradient.\n",
    "- intercept_stderr: Standard error of the intercept.\n",
    "\n",
    "When fitting in Origin or Excel previously you may have come across $R^2$ which has a value between 0 and 1 for a linear fit. This is the rvalue squared.\n",
    "\n",
    "Edit the code below to perform the linear regression and print out several important values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Linear regression\n",
    "result = linregress(x, y)\n",
    "\n",
    "# Output the results in print statements \n",
    "print(f\"Slope: {result.slope:.2f}\") # print to 2 decimal places (2.d.p)\n",
    "print(f\"Intercept: {result.intercept:.2f}\")# print to 2.d.p\n",
    "print(f\"R-squared: {result.___**2:.4f}\")# print to 4.d.p\n",
    "print(f\"Standard error of slope: {result.stderr:.___}\")# print to 2.d.p\n",
    "___(___\"Standard error of intercept: {___.___:___}\")# print to 2.d.p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2e436",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44e486c32c451ed7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Generate the straight line fit.\n",
    "\n",
    "While the fit has now been performed, unlike in Origin or Excel, we don't have anything to plot yet. Therefore we have pass the $x$ values along with our optimised $m$ and $c$ values from the fit to calculate a predicted set of y-values we will call ```y_pred```. Please replace ___ where appropriate below to create the predicted y-values. You should use the variables result.slope, x and result.intercept in the correct places.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the predicted y values using the slope and intercept from the linear regression in the form y = m*x + c\n",
    "y_pred = result.___ * ___ + ___.___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f833c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3ade34209ef14c6a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Plot the scattered data with the straight line fit.\n",
    "\n",
    "Now we want to combine the original data set with the straight line onto a single plot and add text labels that have $m$, $c$ and $R^2$ printed with the correct number of significant figures. Please edit the code below replacing the ___ where appropriate to plot the data and add appropriate text labels using the <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.text.html\">text</a> function.\n",
    "\n",
    "In the example below you will want to use the &plusmn; We can do this in print command using the <a href=\"https://en.wikipedia.org/wiki/List_of_Unicode_characters\">unicode</a> code for the character which for &plusmn; is ```\\u00B1```. If unicode characters are included within f-strings, they will print appropriatly in print and display commands and when generating images should as plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot that shows the original data as a scatter plot and the fitted line\n",
    "\n",
    "#create subplots\n",
    "___, ___ = ___.___()\n",
    "\n",
    "# plot the data as a scatter plot\n",
    "___.___(___, ___, ___=___)\n",
    "\n",
    "# plot the fitted line using plot\n",
    "ax.plot(___, y_pred, color=___, label=___)\n",
    "\n",
    "\n",
    "# set the title of the plot \n",
    "___.___(___)\n",
    "\n",
    "# set the x-axis and y-axis labels\n",
    "___.___(___)\n",
    "___.___(___)\n",
    "\n",
    "\n",
    "# create text f-strings for slope, intercept and R-squared with errors\n",
    "# Format slope +/- error with significant figures correctly formatted\n",
    "# Unicode for plus-minus is \\u00B1\n",
    "slope_text = f\"$m$ = {result.slope:.2f} \\u00B1 {result.stderr:.2f}\"\n",
    "intercept_text = f\"$c$ = {result.intercept:.1f} \\u00B1 {result.intercept_stderr:.1f}\"\n",
    "Rsquared_text = f\"R$^2$ = {result.rvalue**2:.3f}\"\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "# \\n creates a new line\n",
    "# the numbers refer to the position of the text box in axes coordinates (0-1)\n",
    "ax.text(0.03, 0.69, f\"{slope_text}\\n{intercept_text}\\n{Rsquared_text}\",\n",
    "        transform=ax.transAxes,  # relative to axes\n",
    "        fontsize=10,\n",
    "        bbox=dict(facecolor='white', edgecolor='white'))\n",
    "\n",
    "\n",
    "# set legend and show plot\n",
    "___.___()\n",
    "___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a2dab",
   "metadata": {},
   "source": [
    "# Comparing `linregress` and `curve_fit`\n",
    "\n",
    "## Pros and Cons of `linregress`\n",
    "\n",
    "### Pros\n",
    "- **Simple and fast**: Ideal for quick linear regression tasks.\n",
    "- **Built-in statistical metrics**: Returns slope, intercept, standard errors and useful measures of fit.\n",
    "\n",
    "### Cons\n",
    "- **Limited to linear models**: Only fits straight-line relationships.\n",
    "- **No support for custom functions**: Cannot fit non-linear or user-defined models.\n",
    "\n",
    "Therefore in the next few examples we are going to use `curve_fit`\n",
    "\n",
    "`scipy.optimize.curve_fit` is more powerful and flexible, especially when dealing with non-linear relationships.\n",
    "\n",
    "### Pros\n",
    "- **Supports arbitrary functions**: You can define any model (e.g., exponential, logistic, polynomial).\n",
    "- **Handles non-linear regression**: Useful when data doesn't follow a straight-line trend.\n",
    "- **Support for Error-Bars**: \n",
    "\n",
    "### Cons\n",
    "- **No statistical metrics**: It doesn't calculate values like $R^2$ directly, these need to be calculated afterwards\n",
    "- **No Standard Errors**: It doesn't output standard errors directly, but these can be calculated easily\n",
    "\n",
    "To start of with run the code cell below. This generates some random error values called y_err for each data point in our previous data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ed852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "y_err = np.random.uniform(0.5, 1.5, size=x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2822af9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a19e8c595b806d93",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Task 2.1: Write a linear function.\n",
    "\n",
    "As ```curve_fit``` has no built in functions everytime we want to use it we have to make (or import) our own function. As such, you should edit the code below to make a function called linear_fit_function that\n",
    "\n",
    "- takes in variables $x$, $m$ and $c$\n",
    "- calculates $y = mx+c$\n",
    "- **returns** y\n",
    "\n",
    "in the code below you will also see code that looks like\n",
    "\n",
    ">```python\n",
    ">    \"\"\" A function for a linear relationship\n",
    ">\n",
    ">    Args:\n",
    ">        x (float): The x value\n",
    ">        m (float): The gradient of the line\n",
    ">        c (float): The intercept of the line\n",
    ">\n",
    ">    Returns:\n",
    ">        float: The corresponding y value\n",
    ">    \"\"\"\n",
    ">```\n",
    "\n",
    "This is something called a docstring or document string. It explains what the function does and will be printed if you type ```help(linear_fit_function)```. While we won't use them in all the functions we write, when you write your own functions that you will use repeatably its good practice to include docstrings, both to remind you what you did later, and to help other people who use your functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fe269",
   "metadata": {},
   "outputs": [],
   "source": [
    "___ linear_fit_function(___,m,___):\n",
    "    \"\"\" A function for a linear relationship\n",
    "\n",
    "    Args:\n",
    "        x (float): The x value\n",
    "        m (float): The gradient of the line\n",
    "        c (float): The intercept of the line\n",
    "\n",
    "    Returns:\n",
    "        float: The corresponding y value\n",
    "    \"\"\"\n",
    "    y = m*___ + ___\n",
    "    return ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0c166",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fea1419581233d9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Use Curve_fit to fit the linear function and weight by errors on each datapoint.\n",
    "\n",
    "To run ```curve_fit``` using the linear function on the $x$ and $y$ data using the ```y_err``` variable as the errors to use when weighting each variable. Practically what this means is if a datapoint has a large error, it will be considered less important in the fit.\n",
    "\n",
    "In this task simply run the code below to run the fit but its important to understand what each line is doing\n",
    "\n",
    "***explanation of the curve fit function***\n",
    "\n",
    "This uses ```curve_fit``` to fit a user-defined function (linear_fit_function) to the data points (x, y) using non-linear least squares, taking into account the error on each data point (y_err). You set absolute_sigma=True if the errors are measured or taken from measured data which is nearly always the case for data you will obtain.\n",
    "\n",
    "```params``` is then a numpy array that contains all the values in the order the linear function recieves them so ```params[0]``` is $m$ and ```params[1]``` is $c$.\n",
    "\n",
    "```cov``` is something called the covariance matrix, which contains information about all the parameters in the fit. Importantly the line\n",
    "\n",
    ">```python\n",
    ">errors = np.sqrt(np.diag(cov))\n",
    ">```\n",
    "\n",
    "calculates the standard errors for the fit from the covariance matrix where ```errors[0]``` is the error on $m$ and ```errors[1]``` is error on $c$.\n",
    "\n",
    "As before we need to calculate the predicted line which we will call ```y_pred``` we will do this by passing x and the calculated ```params``` back to the linear function\n",
    "\n",
    "\n",
    "\n",
    "note\n",
    "\n",
    ">```python\n",
    ">y_pred = linear_fit_function(x, *params)\n",
    ">```\n",
    "\n",
    "is the quick way of writing\n",
    "\n",
    ">```python\n",
    ">y_pred = linear_fit_function(x, params[0], params[1])\n",
    ">```\n",
    "\n",
    "and is convenient if you have lots of fitting parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b208fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with errors\n",
    "params, cov = curve_fit(linear_fit_function, x, y, sigma=y_err, absolute_sigma=True)\n",
    "# Calculate the standard errors from covariance matrix\n",
    "errors = np.sqrt(np.diag(cov))\n",
    "\n",
    "# Compute predictions\n",
    "y_pred = linear_fit_function(x, params[0], params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7468f53",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c10ec4bf7e163f11",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div class=\"alert alert-success\"><b>Task 2.3: Plot the original datapoints with errorbars and include a line of best fit.</b>\n",
    "\n",
    "Now you've performed the fit using ```curve_fit``` you can plot this data and labels by modifying the code and replacing ___ where appropriate\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "\n",
    ">``` python\n",
    "># create plot using errorbar and plot\n",
    ">fig,ax = plt.subplots()\n",
    ">ax.errorbar(x, y, y_err, label='Data Points with Errors', fmt='o',capsize=2, markersize=4)\n",
    ">ax.plot(x, y_pred, color='red', label='Regression Line')\n",
    ">ax.set_xlabel('X-axis')\n",
    ">ax.set_ylabel('Y-axis')\n",
    ">ax.set_title('Scatter Plot of Linear Data with errors with Noise included fitted line')\n",
    ">\n",
    "># Format slope ± error with significant figures\n",
    ">slope_text = f\"Slope = {params[0]:.2f} \\u00B1 {errors[0]:.2f}\"\n",
    ">intercept_text = f\"Intercept = {params[1]:.1f} \\u00B1 {errors[1]:.1f}\"\n",
    ">\n",
    "># Add annotation in legend-like position\n",
    ">ax.text(0.03, 0.69, f\"{slope_text}\\n{intercept_text}\",\n",
    ">        transform=ax.transAxes,  # relative to axes\n",
    ">        fontsize=10,\n",
    ">        bbox=dict(facecolor='white', edgecolor='white'))\n",
    ">\n",
    ">\n",
    ">ax.legend()\n",
    ">plt.show()\n",
    ">```\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b141d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot that shows the original data as a scatter plot and the fitted line\n",
    "\n",
    "#create subplots\n",
    "___, ___ = ___.___()\n",
    "\n",
    "# plot the data as a errorbar plot\n",
    "ax.___(___, ___, ___, label=___, fmt=___,capsize=___, markersize=___)\n",
    "\n",
    "# plot the fitted line using plot\n",
    "___.___(___, ___, ___, ___)\n",
    "\n",
    "\n",
    "# set the title of the plot \n",
    "___.___(___)\n",
    "\n",
    "# set the x-axis and y-axis labels\n",
    "___.___(___)\n",
    "___.___(___)\n",
    "\n",
    "\n",
    "# create text f-strings for slope, intercept and R-squared with errors\n",
    "# Format slope +/- error with significant figures correctly formatted\n",
    "# Unicode for plus-minus is \\u00B1\n",
    "slope_text = ___\n",
    "intercept_text = ___\n",
    "\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "# \\n creates a new line\n",
    "# the numbers refer to the position of the text box in axes coordinates (0-1)\n",
    "# Add annotation in legend-like position\n",
    "ax.text(___, ___, f\"___\\n___\",\n",
    "        transform=ax.transAxes,  # relative to axes\n",
    "        fontsize=___,\n",
    "        ___=dict(___='white', ___='white'))\n",
    "\n",
    "\n",
    "# set legend and show plot\n",
    "___.___()\n",
    "___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a378b6f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb8c711adc6aebc8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Calculate $R^2$ and the Total Sum of Squares.\n",
    "As highlighted above, the downside of using ```curve_fit``` is that we haven't calculated anything like $R^2$ that allows us to check how well the fit was performed. To do this we would need to write our own functions to do this. Below is a function called R_squared that has been written for you this function does the following\n",
    "\n",
    "- takes in the original $y$ values and the predicted $y_values$\n",
    "- it checks if these two sets of data are the same length\n",
    "- if they are it performs a calculation to calculated $R^2$\n",
    "- it returns the value of $R^2$\n",
    "- it also returns the total sum of squares which is another measure that can be used to check the fit\n",
    "\n",
    "You may not be familiar with the **Total Sum of Squares (SST)** but it is a measure of the total variance in the observed data and simply looks at the distance between each datapoint and the fitted line, and adds all these differences up. Therefore the smaller the value the closer all the data points are to the line. For an individual plot is not always useful, but when you have lots of similar plots it can be useful to identify outliers. \n",
    "\n",
    "run the following cell to define the function ```R_squared``` and then edit the cell below, replacing the __ where appropriate  to calculate and print the values of $R^2$ and the Total Sum of Squares for the fit you have performed using ```curve_fit```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd05fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_squared(y, y_pred):\n",
    "    \"\"\"Compute the R^2 (coefficient of determination) value for the fit.\n",
    "\n",
    "    Args:\n",
    "        y (array-like): The observed y values.\n",
    "        y_pred (array-like): The predicted y values from the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (R^2 value, Total Sum of Squares)\n",
    "               Returns None and prints an error if input lengths do not match.\n",
    "    \"\"\"\n",
    "    if len(y) != len(y_pred):\n",
    "        print(\"Error: y and y_pred must be the same length.\")\n",
    "        return None\n",
    "\n",
    "    # Compute R^2\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared, ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared, ss_tot = R_squared(y, y_pred)\n",
    "print(f\"R-squared = {___:.4f}\")\n",
    "___(___\"Total Sum of Squares = {___:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a2e9a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91c575f84d258da5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Add R<sup>2</sup> and the Total Sum of Squares to a Plot.\n",
    "\n",
    "Now take the code from Task 2.3 to produce a plot of the data with $R^2$ and Total Sum of Squares added as additional text labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot that shows the original data as a scatter plot and the fitted line\n",
    "\n",
    "#create subplots\n",
    "___\n",
    "\n",
    "# plot the data as a error bar plot\n",
    "___\n",
    "\n",
    "# plot the fitted line using plot\n",
    "___\n",
    "\n",
    "\n",
    "# set the title of the plot \n",
    "___\n",
    "# set the x-axis and y-axis labels\n",
    "___\n",
    "___\n",
    "\n",
    "\n",
    "# create text f-strings for slope, intercept and R-squared with errors\n",
    "# Format slope +/- error with significant figures correctly formatted\n",
    "# Unicode for plus-minus is \\u00B1\n",
    "slope_text = ___\n",
    "intercept_text = ___\n",
    "Rsquared_text = ___\n",
    "Total_SST_text = ___\n",
    "\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "# \\n creates a new line\n",
    "# the numbers refer to the position of the text box in axes coordinates (0-1)\n",
    "# Add annotation in legend-like position\n",
    "ax.___(___, ___, f\"___\\n___\\n___\\n___\",\n",
    "        transform=ax.transAxes,  # relative to axes\n",
    "        ___,\n",
    "        ___)\n",
    "\n",
    "\n",
    "# set legend and show plot\n",
    "___.___()\n",
    "___.___()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308d640",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e8babdd9aeae2f1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Beer-Lambert Law Plot.\n",
    "\n",
    "We're now going to re-visit the data file called 'absorption_all.dat' that contains the multiple absorbance measurements for CuSO<sub>4</sub> solutions of various concentrations (in mol dm<sup>-1</sup>) at 800 nm. Using the Pandas function read_csv, Replace the __ characters  in the code below to read in the file and store the data in a pandas Dataframe called 'spectral_data_all', then calculate the ```spectral_data_all['Average']``` and ```spectral_data_all['Error']``` .\n",
    "\n",
    "the line of code\n",
    "\n",
    ">```python\n",
    ">spectral_data_all['Error'] = spectral_data_all['Error'].apply(lambda x: 0.001 if x < 0.001 else x)\n",
    ">```\n",
    "\n",
    "is a quick way to make sure the minimum error is > 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_data_all = pd.read_csv(\"files/absorption_all.dat\")\n",
    "\n",
    "# here axis = 1 means we want to take the mean across the columns (i.e., for each row)\n",
    "# calculate average absorbance\n",
    "spectral_data_all['Average'] = spectral_data_all[['Absorbance_1','Absorbance_2','Absorbance_3']].mean(axis=1)\n",
    "#calculate standard deviation as error\n",
    "spectral_data_all['Error'] = ___\n",
    "# apply minimum error criteria\n",
    "spectral_data_all['Error'] = spectral_data_all['Error'].apply(lambda x: 0.001 if x < 0.001 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1ed79",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70ef5bec3195be83",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Perform a fit and plot a suitable plot for the Beer-Lambert dataset.\n",
    "\n",
    "By modifying the code below and replacing ___ where appropriate please do the following\n",
    "\n",
    "- perform a linear fit on the data set weighting the datapoints by there errors using the ```curve_fit``` function\n",
    "- calculate the predicted y-values and $R^2$ of the fit\n",
    "- plot the datapoints with error bars, predicted line onto the same plots\n",
    "- add title, axis labels and a suitable legende\n",
    "- add text annotations for $m$, $c$ and there errors to a suitable number of significant figures\n",
    "- add a text annotation for $R^2$\n",
    "\n",
    "As you have performed this fit already in the Digital Skills session at the beginning of term, you can check what the fitted parameters should be in advance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2540825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use curve_fit to fit the data with errors using the linear_fit_function defined earlier\n",
    "\n",
    "___, ___ = ___(___, ___[___], ___[___], ___[___], absolute_sigma=True)\n",
    "errors = np.sqrt(np.diag(cov))\n",
    "\n",
    "# Compute predictions, r_squared and ss_tot\n",
    "___ = ___(___, params[___], params[___])\n",
    "r_squared, ss_tot= R_squared(___, ___)\n",
    "\n",
    "\n",
    "#create subplots\n",
    "___\n",
    "\n",
    "# plot the data as a errorbar plot\n",
    "___\n",
    "\n",
    "# plot the fitted line using plot\n",
    "___\n",
    "\n",
    "\n",
    "# set the title of the plot \n",
    "___\n",
    "# set the x-axis and y-axis labels\n",
    "___\n",
    "___\n",
    "\n",
    "\n",
    "# create text f-strings for slope, intercept and R-squared with errors\n",
    "___\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "___\n",
    "\n",
    "\n",
    "# set legend and show plot\n",
    "___.___()\n",
    "___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe476022",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbe97f2ee050fac6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div class=\"alert alert-success\"><b>Task 4.1: Read in Multiple x, y datasets.</b>\n",
    "\n",
    "In the files folder you will find a file called 'scatter_datasets.csv' which contains the $x$ an $y$ data for 18 different scatter plots. Please run the code below to make a Dataframe called Scatter_Data that reads in this file and then display the head of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Scatter_Data = pd.read_csv(\"files/scatter_datasets.csv\")\n",
    "# display first 5 lines\n",
    "Scatter_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2126286",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c232e7750e119126",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Producing a Matrix or Grid of Small Plots for Visulisation of Large Datasets.\n",
    "\n",
    "Here, displaying the dataframe confirms the data is imported but doesn't really tell you anything about the data, If this was experimental data you had collected you might want to quickly visualizs all the data, checking for any anomalies or outliers before you spent time performing fits or analysis. To do this quickly we can use the <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.gridspec.GridSpec.html\">GridSpec Tools</a> we imported at the beginning of this workshop. This is a little like subplots but allows us to make a Grid that we can quickly populate with data.\n",
    "\n",
    "As we know the Dataframe contains $x$ and $y$ columns in pairs we can use the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\">iloc</a> function of Pandas to loop through pairs of columns and set them to $x$ and $y$ before adding them to a plot. We can also use commands like\n",
    "\n",
    ">``` python\n",
    ">ax.set_xticks([])\n",
    ">```\n",
    "\n",
    "to remove tick labels to end up with simple grid of plots that allows us to easily visualise the data quickly. What you plot the data here, you should see that the last two plots look nothing like the other datasets\n",
    "\n",
    "The line of code ```gs = gridspec.GridSpec(6, 6, wspace=0, hspace=0)``` has created a grid of 6 rows and 6 columns with no whitespace between each plot. When arranging items in a grid, you then need to calculate the **row** and **column** position of each item based on its index `i`. This is where integer division (`//`) and the modulo operator (`%`) come in handy.\n",
    "\n",
    "In the line of code ```row = i // 6```\n",
    "\n",
    "- This uses **integer division** to determine the row number.\n",
    "- It divides `i` by 6 and **discards the remainder**, giving you the number of complete rows before item `i`.\n",
    "- For example:\n",
    "  - If `i = 13`, then `13 // 6 = 2`, so the item is in **row 2**.\n",
    "  - If `i = 5`, then `5 // 6 = 0`, so the item is in **row 0**.\n",
    "\n",
    "This means every 6 items, you move to the next row.\n",
    "\n",
    "In the line of code ```col = i % 6```\n",
    "\n",
    "- This uses the **modulo operator**, which gives the **remainder** after division.\n",
    "- It tells you the **column position** within the current row.\n",
    "- For example:\n",
    "  - If `i = 13`, then `13 % 6 = 1`, so the item is in **column 1**.\n",
    "  - If `i = 5`, then `5 % 6 = 5`, so the item is in **column 5**.\n",
    "\n",
    "It’s useful for **cycling through a fixed range**. In this case, it cycles through column indices `0` to `5`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Example Table of row and column combinations\n",
    "\n",
    "\n",
    "| `i` | `row = i // 6` | `col = i % 6` |\n",
    "|-----|----------------|---------------|\n",
    "| 0   | 0              | 0             |\n",
    "| 1   | 0              | 1             |\n",
    "| 5   | 0              | 5             |\n",
    "| 6   | 1              | 0             |\n",
    "| 13  | 2              | 1             |\n",
    "\n",
    "There is nothing to edit in the cell below, run the code and look at the plot produces, then try playing with some of the numbers so see how this changes the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and gridspec\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "# wspace=0, hspace=0 removes space between plots\n",
    "gs = gridspec.GridSpec(6, 6, wspace=0, hspace=0)\n",
    "\n",
    "# Iterate over column pairs directly using iloc\n",
    "num_pairs = Scatter_Data.shape[1] // 2\n",
    "\n",
    "for i in range(num_pairs):\n",
    "    x = Scatter_Data.iloc[:, 2*i]\n",
    "    y = Scatter_Data.iloc[:, 2*i + 1]\n",
    "\n",
    "    #calculate row and column for subplot\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    #uses gridespec to place subplots in correct location\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    ax.scatter(x, y, s=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6230d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d09e9d3242ab2902",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Producing a Matrix or Grid of Small Plots for Visulisation of Large Datasets with Fitted Parameters.\n",
    "\n",
    "Now produce the same plot, but this time by replacing ___ where appropriate, uses curve_fit within the for loop to fit each dataset, adding a fitted line and $R^2$ value to each plot in the Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and gridspec\n",
    "fig = plt.___(___=(12, 12))\n",
    "gs = gridspec.___(___, ___, ___=0, ___=0)\n",
    "\n",
    "# Iterate over column pairs directly using iloc\n",
    "num_pairs = ___\n",
    "\n",
    "for i in range(___):\n",
    "    x = Scatter_Data.iloc[___, ___]\n",
    "    y = ___.___[___, ___]\n",
    "\n",
    "    row = ___ // ___\n",
    "    col = ___ % ___\n",
    "    ax = ___.___(gs[___, ___])\n",
    "    # add scatter plot\n",
    "    ax.___(___, ___, s=___)\n",
    "    # remove x and y ticks\n",
    "    ___\n",
    "    ___\n",
    "\n",
    "    \n",
    "    # Fit with curve_fit\n",
    "    ___, ___ = ___(___, ___, ___)\n",
    "    # calculate errors from covariance matrix\n",
    "    errors = np.___(___.___(___))\n",
    "    \n",
    "    # Compute predictions and R-squared and ss_tot\n",
    "    y_pred = linear_fit_function(___, ___, ___)\n",
    "    r_squared, ss_tot = R_squared(___, ___)\n",
    "\n",
    "    # add fitted line to plot\n",
    "    ax.plot(___, ___, color=___)\n",
    "    # create R-squared text\n",
    "    Rsquared_text = ___\n",
    "\n",
    "    # Add annotation in legend-like position\n",
    "    # needs to be inside the for loop to add to each subplot\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0226c7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c88972abb13480b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Producing a Matrix or Grid of Small Plots for Visulisation of Large Datasets with Fitted Parameter and a Summary Dataframe.\n",
    "\n",
    "Now modify the code below to extend the code from Task 4.3 to create Dictionary of information within the loop that can be converted to a Dataframe, summarising the key fitting parameters. Then display the plot and Dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29013d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and gridspec\n",
    "fig = ___\n",
    "gs = ___\n",
    "\n",
    "# Iterate over column pairs directly using iloc\n",
    "num_pairs = ___\n",
    "\n",
    "# Prepare results list\n",
    "results = []\n",
    "\n",
    "for ___ in ___\n",
    "    x = ___\n",
    "    y = ___\n",
    "\n",
    "    row = ___ // ___\n",
    "    col = ___ % ___\n",
    "    ax = ___\n",
    "    # add scatter plot\n",
    "    ___\n",
    "    # remove x and y ticks\n",
    "    ___\n",
    "    ___\n",
    "\n",
    "    \n",
    "    # Fit with curve_fit\n",
    "    ___, ___ = ___(___, ___, ___)\n",
    "    # calculate errors from covariance matrix\n",
    "    errors = np.___(___.___(___))\n",
    "    \n",
    "    # Compute predictions and R-squared and ss_tot\n",
    "    y_pred = ___\n",
    "    r_squared, ss_tot = ___\n",
    "\n",
    "    # add fitted line to plot\n",
    "    ___\n",
    "    # create R-squared text\n",
    "    Rsquared_text = ___\n",
    "\n",
    "    # Add annotation in legend-like position\n",
    "    # needs to be inside the for loop to add to each subplot\n",
    "    ___\n",
    "\n",
    "\n",
    "    results.append({\n",
    "    \"X_column\": Scatter_Data.columns[2*i],\n",
    "    \"Y_column\": Scatter_Data.___[___],\n",
    "    \"Slope\": ___,\n",
    "    \"Intercept\": ___,\n",
    "    \"Slope_error\": ___,\n",
    "    \"Intercept_error\": ___,\n",
    "    \"R_squared\": ___\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create figure and gridspec\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "gs = gridspec.GridSpec(6, 6, wspace=0, hspace=0)\n",
    "\n",
    "# Iterate over column pairs directly using iloc\n",
    "num_pairs = Scatter_Data.shape[1] // 2\n",
    "\n",
    "# Prepare results list\n",
    "results = []\n",
    "\n",
    "\n",
    "for i in range(num_pairs):\n",
    "    x = Scatter_Data.iloc[:, 2*i]\n",
    "    y = Scatter_Data.iloc[:, 2*i + 1]\n",
    "\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    ax.scatter(x, y, s=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    \n",
    "    params, cov = curve_fit(linear_fit_function, x, y)\n",
    "    errors = np.sqrt(np.diag(cov))\n",
    "    \n",
    "    \n",
    "    y_pred = linear_fit_function(x, params[0], params[1])\n",
    "    r_squared, ss_tot = R_squared(y, y_pred)\n",
    "\n",
    "\n",
    "    ax.plot(x, y_pred, color='red')\n",
    "    Rsquared_text = f\"R$^2$ = {r_squared:.3f}\"\n",
    "\n",
    "    # Add annotation in legend-like position\n",
    "    ax.text(0.05, 0.8, f\"{Rsquared_text}\",\n",
    "        transform=ax.transAxes,  # relative to axes\n",
    "        fontsize=6,\n",
    "        bbox=dict(facecolor='white', edgecolor='white'))\n",
    "    \n",
    "\n",
    "    # creates a dictionary of the data for each fit and appends to results list\n",
    "    results.append({\n",
    "        \"X_column\": Scatter_Data.columns[2*i],\n",
    "        \"Y_column\": Scatter_Data.columns[2*i + 1],\n",
    "        \"Slope\": params[0],\n",
    "        \"Intercept\": params[1],\n",
    "        \"Slope_error\": errors[0],\n",
    "        \"Intercept_error\": errors[1],\n",
    "        \"R_squared\": r_squared\n",
    "\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "fit_results_df = pd.DataFrame(results)\n",
    "# Display the fit results DataFrame\n",
    "display(fit_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf4e1a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8be697e8770bd91d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div class=\"alert alert-warning\"><b>Advanced Task: Add plot images to a Dataframe.</b>\n",
    "\n",
    "This is a task thats included to simply show how far you can take visulisations, to do this we will need to import several more packages but what we're trying to do is mimic what the RDkit Pandastools did by generating images of each plot and adding them to the dataframe. As such modify the code below using that from earlier to perform the fitting, generate the plots and the dataframe. The code block\n",
    "\n",
    ">``` python\n",
    ">    buf = BytesIO()\n",
    ">    fig.savefig(buf, format='png')\n",
    ">    plt.close(fig)\n",
    ">    image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    ">    img_html = f'<img src=\"data:image/png;base64,{image_base64}\" width=\"100\" height=\"100\">'\n",
    ">    buf.close()\n",
    ">```\n",
    "\n",
    "then stops the plot printing to screen, but instead stores the raw code of the image as a variable called ```img_html```\n",
    "\n",
    "This can then be added to the dictionary as an extra column\n",
    "\n",
    "to view these images we have to use a slightly modified display command\n",
    "\n",
    ">``` python\n",
    "> display(HTML(fit_results_df.to_html(escape=False)))\n",
    ">```\n",
    "\n",
    "This converts the Dataframe to a HTML file before displaying it which allows Jupyter to display the image of each plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Create figure and gridspec\n",
    "fig = ___\n",
    "gs = ___\n",
    "\n",
    "# Iterate over column pairs directly using iloc\n",
    "num_pairs = ___\n",
    "\n",
    "# Prepare results list\n",
    "results = []\n",
    "\n",
    "for ___ in ___\n",
    "    x = ___\n",
    "    y = ___\n",
    "\n",
    "    row = ___ // ___\n",
    "    col = ___ % ___\n",
    "    ax = ___\n",
    "    # add scatter plot\n",
    "    ___\n",
    "    # remove x and y ticks\n",
    "    ___\n",
    "    ___\n",
    "\n",
    "\n",
    "   \n",
    "    # Fit with curve_fit\n",
    "    ___, ___ = ___(___, ___, ___)\n",
    "    # calculate errors from covariance matrix\n",
    "    errors = np.___(___.___(___))\n",
    "    \n",
    "    # Compute predictions and R-squared and ss_tot\n",
    "    y_pred = ___\n",
    "    r_squared, ss_tot = ___\n",
    "\n",
    "    # add fitted line to plot\n",
    "    ___\n",
    "    # create R-squared text\n",
    "    Rsquared_text = ___\n",
    "\n",
    "    # Add annotation in legend-like position\n",
    "    # needs to be inside the for loop to add to each subplot\n",
    "    ___\n",
    "\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "    img_html = f'<img src=\"data:image/png;base64,{image_base64}\" width=\"100\" height=\"100\">'\n",
    "    buf.close()\n",
    "\n",
    "\n",
    "    results.append({\n",
    "    \"X_column\": ___,\n",
    "    \"Y_column\": ___,\n",
    "    \"Slope\": ___,\n",
    "    \"Intercept\": ___,\n",
    "    \"Slope_error\": ___,\n",
    "    \"Intercept_error\": ___,\n",
    "    \"R_squared\": ___,\n",
    "    \"Plot\": img_html\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame and display with embedded images\n",
    "fit_results_df = pd.DataFrame(results)\n",
    "display(HTML(fit_results_df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717867e",
   "metadata": {},
   "source": [
    "If we assume that these data are repeats of the same experiment, we should attempt to combine this into a single value (say slope) with an uncertainity, we can clearly see that the final two rows are anomalous so these should be excluded. When combining multiple slope values we have two options\n",
    "\n",
    "1. Simply work out the mean of the slope values and use the standard deviation of the slope values as an estimate of the error, this however does not take into account the error on each individual slope.\n",
    "\n",
    "2. Instead we could use a **weighted average** which accounts for the reliability of each measurement. This is particularly useful when each slope has an associated uncertainty and we are confident in these uncertainties.\n",
    "\n",
    "# Weighted Average of Slopes\n",
    "\n",
    "\n",
    "\n",
    "Given we have a number of slope values:\n",
    "\n",
    "$$m_1, m_2, \\dots, m_n$$  \n",
    "\n",
    "and associated uncertainties:\n",
    "\n",
    "$$\\sigma_1, \\sigma_2, \\dots, \\sigma_n$$\n",
    "\n",
    "The **weights** are defined as the inverse of the uncertainty squared (technically this is the variance):\n",
    "\n",
    "$$\n",
    "w_i = \\frac{1}{\\sigma_i^2}\n",
    "$$\n",
    "\n",
    "The **weighted average slope** is:\n",
    "\n",
    "$$\n",
    "\\bar{m}_{\\text{weighted}} = \\frac{\\sum_{i=1}^{n} w_i m_i}{\\sum_{i=1}^{n} w_i}\n",
    "$$\n",
    "\n",
    "The **standard error** of the weighted average is:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\bar{m}} = \\sqrt{\\frac{1}{\\sum_{i=1}^{n} w_i}}\n",
    "$$\n",
    "\n",
    "## Why Would We Use Weighted Averages?\n",
    "\n",
    "- Gives more influence to precise measurements.\n",
    "- Reduces the impact of noisy or uncertain data.\n",
    "- Provides a statistically sound estimate of the true slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9493f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03c892c420be4ae5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Create a function that determines the weighted Average and associated error.</b>\n",
    "\n",
    "Modify the code below by replacing the ___ to create a function that calculates and returns both the weighted average and weighted error for a series of values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted average function\n",
    "___ weighted_avg_and_error(___, ___):\n",
    "    \"\"\"\n",
    "    Calculate the weighted average and its standard error.\n",
    "\n",
    "    Parameters:\n",
    "    - slopes (array-like): A list or array of slope values.\n",
    "    - errors (array-like): A list or array of standard errors associated with each slope.\n",
    "\n",
    "    Returns:\n",
    "    - weighted_avg (float): The weighted average of the slopes.\n",
    "    - weighted_error (float): The standard error of the weighted average.\n",
    "\n",
    "    Notes:\n",
    "    - Weights are computed as the inverse of the variance (1 / error^2).\n",
    "    - This method gives more influence to slopes with smaller errors.\n",
    "    \"\"\"\n",
    "    weights = 1 / errors**2\n",
    "    weighted_avg = np.sum(slopes * weights) / np.sum(weights)\n",
    "    weighted_error = np.sqrt(1 / np.sum(weights))\n",
    "    ___ ___, ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01812c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0bacd6365d4a82c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Create a function that determines the weighted Average and associated error.</b>\n",
    "\n",
    "Create a modified dataset that removes rows that have an $R^2$ value of < 0.8. Then determine and print the weighted average of the slope with its associated uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acca4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame excluding fits with R_squared < 0.8\n",
    "df_excluded = fit_results_df[fit_results_df[___ >= ___]\n",
    "# calculate weighted average slope and error\n",
    "slope_avg, slope_err = weighted_avg_and_error(df_excluded[___], ___[___])\n",
    "# produce a useful print statement\n",
    "print(_\"Weighted Average Slope (R^2 >= 0.8): {___:___} \\u00B1 {___:___}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72e150",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8091662e8ffc7d55",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Non-Linear Curve Fitting.\n",
    "\n",
    "We will now look at fitting to a non-linear function. Firstly modify the code below by replacing the ___ where appropriate to generate some data that creates an exponential decay, with some noise added to the data points. Then plot this as a scatter plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator with a fixed seed for reproducibility\n",
    "rng = np.random.___(seed=___)\n",
    "\n",
    "# Generate 100 x values between 0 and 5\n",
    "x = np.linspace(___, ___, ___)\n",
    "\n",
    "# Generate exponential decay data with reduced noise\n",
    "y_decay = np.exp(-2*x) + rng.normal(scale=0.03, size=x.___)\n",
    "\n",
    "# create subplots\n",
    "___\n",
    "# plot scatter alpha changes the transparency of the points\n",
    "ax.scatter(___,___,color=__, alpha=0.7, label='Noisy Exponential Decay')\n",
    "\n",
    "# set title and labels\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "#set grid alpha allows you to set the transparency of the grid lines\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# create legend and show plot\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94667479",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f56c9201d5fa5c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Create and Exponential Decay Function.</b>\n",
    "\n",
    "As ```curve_fit``` has no built in functions everytime we want to use it we have to make (or import) our own function. As such, you should edit the code below to make a function called exp_decay that:\n",
    "\n",
    "- takes in variables $x$, $a$ and $b$\n",
    "- calculates $ae^{-bx}$\n",
    "- **returns** the answer to this equation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af658a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exponential decay function\n",
    "def exp_decay(___, ___, ___):\n",
    "    \"\"\" A function for exponential decay\n",
    "        Args:\n",
    "            x (float): The x value\n",
    "            a (float): The initial amplitude\n",
    "            b (float): The decay constant\n",
    "    \n",
    "        Returns:\n",
    "            float: The corresponding y value\n",
    "    \"\"\"\n",
    "    return ___ * ___.exp(-___ * ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd06ef",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-891624e143b108cc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Non-Linear Curve Fitting.\n",
    "\n",
    "Now modify the code below such that you uses ```curve_fit``` to fit the exp_decay function to the data. Then generate the plot with\n",
    "\n",
    "- Data points\n",
    "- Calculated line\n",
    "- titles, labels and legend\n",
    "- text labels for $a$ and $b$ with errors to the correct level of certainty, along with $R^2$\n",
    "\n",
    "importantly in the code below\n",
    "\n",
    ">```python\n",
    "> p0=(0.5, 0.5)\n",
    ">```\n",
    "\n",
    "is used to initialise $ a = 0.5$ and $ b = 0.5 $\n",
    "\n",
    "These are just initial guesses for the values, but for non-linear functions, its often important to provide a sensible initial guess for parameters, otherwise the fitting procedure may fail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the curve using curve_fit with the exponential decay function\n",
    "___, ___ = ___(___, ___, ___,p0=(0.5, 0.5))  # initial guess a=0.5, b=0.5\n",
    "# calculate errors from covariance matrix\n",
    "___\n",
    "\n",
    "# Generate fitted curve\n",
    "y_pred = ___\n",
    "# determine  R-squared and ss_tot\n",
    "___\n",
    "\n",
    "# create plot using subplots\n",
    "___\n",
    "\n",
    "# generate scatter plot\n",
    "___\n",
    "\n",
    "# generate fitted line plot\n",
    "___\n",
    "\n",
    "# set title and labels\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Format slope ± error with significant figures\n",
    "a_text = ___\n",
    "b_text = f___\n",
    "Rsquared_text = ___\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "___\n",
    "\n",
    "\n",
    "# add legend, grid and show the plot\n",
    "___\n",
    "___\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4de07",
   "metadata": {},
   "source": [
    "While we have included $R^2$ on the plot above this is not really an appropriate measure of the goodness-of-fit as the traditional definition of $$R^2$$ is based on linear regression assumptions. Applying it to non-linear models can produce misleading values that do not accurately reflect fit quality. As such, we should be looking for alternatives when possible\n",
    "\n",
    "These can include:\n",
    "\n",
    "1. **Residual Analysis**\n",
    "Examine the residuals (which is the essentially the difference between the data point and the fit):\n",
    "$$\n",
    "\\text{Residual}_i = y_i - \\hat{y}_i\n",
    "$$\n",
    "- Plot residuals vs. fitted values can be useful.\n",
    "- Here you want to look for systematic patterns in the residuals which suggest a poor fit.\n",
    "- If the residuals are small and random distributed around zero then the fit is likely good\n",
    "\n",
    "2. **Root Mean Squared Error (RMSE)**\n",
    "Measures the average magnitude of the residuals:\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "- Sensitive to large errors.\n",
    "- Useful for comparing model performance across datasets.\n",
    "\n",
    "3. **Mean Absolute Error (MAE)**\n",
    "Measures the average absolute difference between predicted and actual values:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "- Less sensitive to outliers than RMSE.\n",
    "- Easier to interpret in terms of average\n",
    "\n",
    "In the code cell below we have written functions that calculate these three parameters, run the cell to define the three functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed54e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate residuals between observed and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): Actual observed values.\n",
    "    - y_pred (array-like): Predicted values from the model.\n",
    "\n",
    "    Returns:\n",
    "    - residuals (np.ndarray): Array of residuals (y_true - y_pred),\n",
    "      or None if input lengths do not match.\n",
    "    \"\"\"\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return None\n",
    "    return np.array(y_true) - np.array(y_pred)\n",
    "\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Error (RMSE) between observed and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): Actual observed values.\n",
    "    - y_pred (array-like): Predicted values from the model.\n",
    "\n",
    "    Returns:\n",
    "    - rmse (float): Root Mean Squared Error,\n",
    "      or None if input lengths do not match.\n",
    "    \"\"\"\n",
    "    residuals = calculate_residuals(y_true, y_pred)\n",
    "    if residuals is None:\n",
    "        return None\n",
    "    return np.sqrt(np.mean(residuals**2))\n",
    "\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Error (MAE) between observed and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): Actual observed values.\n",
    "    - y_pred (array-like): Predicted values from the model.\n",
    "\n",
    "    Returns:\n",
    "    - mae (float): Mean Absolute Error,\n",
    "      or None if input lengths do not match.\n",
    "    \"\"\"\n",
    "    residuals = calculate_residuals(y_true, y_pred)\n",
    "    if residuals is None:\n",
    "        return None\n",
    "    return np.mean(np.abs(residuals))\n",
    "\n",
    "print(\"Functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c173f7d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1acf44bf0ecd0cba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Non-Linear Curve Fitting include RMSE.\n",
    "\n",
    "Now duplicate the plot from Task 5.3 but add Total Sum of Squares and RMSE and remove $R^2$ from the plot\n",
    "\n",
    "\n",
    ">        fontsize=10,\n",
    ">        bbox=dict(facecolor='none', edgecolor='none'))\n",
    ">\n",
    ">plt.legend()\n",
    ">plt.grid(alpha=0.3)\n",
    ">plt.show()\n",
    ">```\n",
    "\n",
    "\n",
    "Just for interest if you had plotted the residuals for this plot using the following code\n",
    "\n",
    ">```python\n",
    "># Calculate residuals\n",
    ">residuals = calculate_residuals(y, y_pred)\n",
    ">\n",
    "># Plot residuals\n",
    ">fig, ax = plt.subplots(figsize=(8, 4))\n",
    ">ax.scatter(x, residuals, color='blue', alpha=0.6)\n",
    ">ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    ">ax.set_title('Residuals Plot')\n",
    ">ax.set_xlabel('x-axis')\n",
    ">ax.set_ylabel('Residuals (Observed - Predicted)')\n",
    ">plt.grid(alpha=0.3)\n",
    ">plt.tight_layout()\n",
    ">plt.show()\n",
    ">```\n",
    "\n",
    "you would have got this plot\n",
    "\n",
    "![Residuals plot showing the majority of residuals greater than 0](files/residuals.png)\n",
    "\n",
    "You should note here that the residuals are not around zero which would be surprising if this was real data. The reason its not is that we generated the data by adding noise using the <a href=\"https://numpy.org/doc/2.1/reference/random/generated/numpy.random.normal.html\">normal</a> function in numpy which creates noise that is Normally or Gaussian distributed.\n",
    "\n",
    "you could see this using this code\n",
    "\n",
    ">``` python\n",
    ">from scipy.stats import norm\n",
    ">\n",
    "># Plot histogram of residuals\n",
    ">fig, ax = plt.subplots(figsize=(8, 4))\n",
    ">n, bins, patches = ax.hist(residuals, bins=15, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n",
    ">\n",
    ">#Compute mean and standard deviation of residuals\n",
    ">mu = np.mean(residuals)\n",
    ">std = np.std(residuals)\n",
    ">\n",
    "># Overlay normal distribution curve\n",
    ">x_vals = np.linspace(min(bins), max(bins), 100)\n",
    ">pdf = norm.pdf(x_vals, mu, std)\n",
    ">ax.plot(x_vals, pdf, 'r--', label=f'Normal Dist.\\nμ={mu:.2f}, σ={std:.2f}')\n",
    ">\n",
    ">ax.set_title('Histogram of Residuals')\n",
    ">ax.set_xlabel('Residual Value')\n",
    ">ax.set_ylabel('Density')\n",
    ">ax.legend()\n",
    ">plt.grid(alpha=0.3)\n",
    ">plt.tight_layout()\n",
    ">plt.show()\n",
    ">```\n",
    "\n",
    "which would generate this plot\n",
    "\n",
    "![showing the normal distribution of the residuals](files/normal.png)\n",
    "\n",
    "showing the clear normal distribution of the residuals as expected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the curve using curve_fit with the exponential decay function\n",
    "___  # initial guess a=0.5, b=0.5\n",
    "# calculate errors from covariance matrix\n",
    "___\n",
    "\n",
    "# Generate fitted curve\n",
    "___\n",
    "# determine  R-squared and ss_tot\n",
    "___\n",
    "\n",
    "# determine RMSE\n",
    "rmse = ___\n",
    "\n",
    "# create plot using subplots\n",
    "___\n",
    "\n",
    "# generate scatter plot\n",
    "___\n",
    "\n",
    "# generate fitted line plot\n",
    "___\n",
    "\n",
    "# set title and labels\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Format slope ± error with significant figures\n",
    "a_text = ___\n",
    "b_text = ___\n",
    "TSS_text = ___\n",
    "RMSE_text = ___\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "___\n",
    "\n",
    "\n",
    "# add legend, grid and show the plot\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit the curve\n",
    "params, covariance = curve_fit(exp_decay, x, y_decay,p0=(0.5, 0.5))  # initial guess a=0.5, b=0.5\n",
    "errors = np.sqrt(np.diag(covariance))\n",
    "\n",
    "# Generate fitted curve\n",
    "y_pred = exp_decay(x, params[0], params[1])\n",
    "r_squared, ss_tot = R_squared(y_decay, y_pred)\n",
    "rmse = calculate_rmse(y_decay, y_pred)\n",
    "\n",
    "# Plot noisy data and fitted curve\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.scatter(x, y_decay, color='purple', alpha=0.6, label='Noisy Data')\n",
    "ax.plot(x, y_pred, color='orange', linewidth=2, label=f'Fitted Curve')\n",
    "ax.set_title('Curve Fit for Exponential Decay')\n",
    "ax.set_xlabel('x-axis')\n",
    "ax.set_ylabel('y-axis')\n",
    "\n",
    "# Format slope ± error with significant figures\n",
    "a_text = f\"a = {params[0]:.2f} \\u00B1 {errors[0]:.2f}\"\n",
    "b_text = f\"b = {params[1]:.2f} \\u00B1 {errors[1]:.2f}\"\n",
    "TSS_text = f\"Total Sum of Squares = {ss_tot:.3f}\"\n",
    "RMSE_text = f\"RMSE = {rmse:.3f}\"\n",
    "\n",
    "# Add annotation in legend-like position\n",
    "ax.text(0.59, 0.69, f\"{a_text}\\n{b_text}\\n{TSS_text}\\n{RMSE_text}\",\n",
    "        transform=ax.transAxes,  # relative to axes\n",
    "        fontsize=10,\n",
    "        bbox=dict(facecolor='none', edgecolor='none'))\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
